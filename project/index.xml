<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Fan-Keng Sun</title>
    <link>https://Daikon-Sun.github.io/project/</link>
    <description>Recent content in Projects on Fan-Keng Sun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Tue, 13 Nov 2018 00:00:00 +0800</lastBuildDate>
    
	<atom:link href="https://Daikon-Sun.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>AI Traffic Control System [CTCI Scholarship]</title>
      <link>https://Daikon-Sun.github.io/project/ctci/</link>
      <pubDate>Tue, 13 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/ctci/</guid>
      <description>Due to the high population density and popular usage of private car in Taiwan, traffic jam is a serious problem in Taiwan&amp;rsquo;s major cities, especially Taipei, Tainan, and Kaohsiung. Most traffic jam can be alleviated if all traffic signals are dynamically adjusted and optimized at different location and time period. Following the idea, we designed and implemented a low-cost and real-time traffic signal system on NVIDIA Jetson TK1 using Fast-RCNN to detected the traffic flow and reinforcement learning to train the traffic signal switching interval model.</description>
    </item>
    
    <item>
      <title>Anime Generation by Generative Adversarial Networks</title>
      <link>https://Daikon-Sun.github.io/project/anime_gan/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/anime_gan/</guid>
      <description>Our work includes two stages. In the first stage we trained the Conditional GAN with only hair color and eyes color features. Then, a series of five corresponding anime images is produced. In the second stage, we proceeded further by collecting more features from the dataset, and by feeding more complicated input sentence, desired feature is then learned by Conditional GAN. We were then able to synthesis anime character with glasses or no glasses, along with different hair styles.</description>
    </item>
    
    <item>
      <title>Functionally Reduced And-Inverter Graph (FRAIG)</title>
      <link>https://Daikon-Sun.github.io/project/fraig/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/fraig/</guid>
      <description>In this project, I implemented a special circuit representation, FRAIG, from a circuit description file.
The program performs the following processes:
 Parse a circuit description file in the AIGER format. Sweep out the gates that cannot be reached from primary outputs (excluding primary inputs). After this operation, all the gates that are originally “defined-but-not-used” will be deleted. Perform trivial circuit optimizations without altering the functionality, such as replacing a always-inverse fan-ins of an AND gate by a constant zero.</description>
    </item>
    
    <item>
      <title>High Dynamic Range (HDR) Imaging</title>
      <link>https://Daikon-Sun.github.io/project/hdr/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/hdr/</guid>
      <description>We assemble high dynamic range (HDR) images from a series of photographs under various exposures.
The features we have implemented are:
 Image alignment: median threshold bitmap algorithm. HDR imaging: Paul Debevec&amp;rsquo;s method. Tone mapping: Erik Reinhard&amp;rsquo;s method. Exposure fusion: Tom Mertens&amp;rsquo; method. Blob removal: rule-based method. Ghost removal: EA Khan&amp;rsquo;s method.  </description>
    </item>
    
    <item>
      <title>Image Stitching (Panorama)</title>
      <link>https://Daikon-Sun.github.io/project/panorama/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/panorama/</guid>
      <description>We construct panoramas from a series of photographs. The following feature-based process is run through in the order to create panoramas:
 Feature detection: scale invariant feature transform (SIFT) or multi-scale oriented patches (MSOP), with the aid of exhaustive search. Feature matching: exhaustive search and Haar’s method. Projection: cylindrical projection. Image stitching: bundle adjustment. Blending: multi-band blending.  </description>
    </item>
    
    <item>
      <title>Physical Design for Nanometer ICs</title>
      <link>https://Daikon-Sun.github.io/project/physical_design/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/physical_design/</guid>
      <description>Four stages in the flow of Physical Design for Nanometer ICs are included in this project. The four stages are sorted in the order as if in actual design flow:
1. Fiduccia-Mattheyses heuristic for solving 2-way, balanced VLSI hypergraph partitioning, 
2. B-star-tree with fast-simulated-annealing for solving fixed-outline floorplan problem, 
3. Abacus-based Legalizer with exact cost for solving single-cell height legalization, 
4. Efficient steiner tree construction based on spanning graphs.</description>
    </item>
    
    <item>
      <title>Playing Against AlphaGo Zero on Raspberry Pi</title>
      <link>https://Daikon-Sun.github.io/project/pi_go/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/pi_go/</guid>
      <description>We use two open source AlphaGo Zero re-implementation: Leela-Zero and PhoenixGo, which are both super-human AI. An user can play againt Alpha-Go on a Raspberry Pi (RPi) with a touch screen. If there is Internet connection, the RPi is connected to a server with GPU, and the communication is defined by the GTP protocol (ver 2). Otherwise, the user can play against a weaker version of AlphaGo Zero locally. A chatroom is also implemented so that two humans can play Go together.</description>
    </item>
    
    <item>
      <title>Smart Equivalence Checking: Program-Building for Name Mapping</title>
      <link>https://Daikon-Sun.github.io/project/luluec/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/luluec/</guid>
      <description>This project won the 3rd place in the Problem A at 2018 ICCAD CAD contest.
Introduction In the ASIC design flow, implementation tools change the names of design components to comply with the implementation rules while still keeping the information to track the design intention. For example, tools change the name &amp;ldquo;a[0]&amp;rdquo; into &amp;ldquo;a_0_&amp;rdquo; to follow the rule: “no special character”. Meanwhile, name mapping plays an important role in verification tools because good name mapping can help verification tools efficiently and correctly verify designs.</description>
    </item>
    
    <item>
      <title>Solving Multi-Armed Bandits by Upper Confidence Bound (UCB) Algorithms</title>
      <link>https://Daikon-Sun.github.io/project/mpml/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/mpml/</guid>
      <description>The most simple example of the exploration versus exploitation dilemma is the stochastic multi-armed bandits (MAB) problem. Several algorithms have been proposed to tackle MAB problem, among them, algorithms based on upper confidence bound are the most successful and widely-used. Since the first paper about UCB [1] came out in 2002, there have been an ongoing research (UCBV, improved-UCB, EUCBV, MOSS, OCUCB) in improving the strategy to obtain a lower regret bound.</description>
    </item>
    
    <item>
      <title>What does Deep CNN learn? Visualization of Popular Deep CNN Models</title>
      <link>https://Daikon-Sun.github.io/project/cnn_vis/</link>
      <pubDate>Sat, 03 Nov 2018 00:00:00 +0800</pubDate>
      
      <guid>https://Daikon-Sun.github.io/project/cnn_vis/</guid>
      <description>Introduction Convolutional Neural Network (CNN) was first proposed by Y. LeCun et al. in 1989, who successfully trained a CNN for digit classification. However, not until 2012, when A.Krizhevsky et al. applied this architecture in ILSVRC-2012 competition and won the first place with top-5 error rates of 15.3% (which improves by more than 10% compared to previous feature engineering methods), did CNN take over computer vision. In recent years, the advance of GPU, the availability of much larger training sets, and better model regularization strategies all contribute to the dramatic improvement in performance.</description>
    </item>
    
  </channel>
</rss>